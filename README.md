# ðŸ§  Programming Project Clustering Based on README.md Text Analysis  
*(PhÃ¢n cá»¥m Dá»± Ã¡n Láº­p trÃ¬nh Dá»±a trÃªn PhÃ¢n tÃ­ch VÄƒn báº£n README.md)*

![Python](https://img.shields.io/badge/Python-3.10+-3776AB?style=flat&logo=python)
![ScikitLearn](https://img.shields.io/badge/Scikit--Learn-Machine_Learning-F7931E?style=flat&logo=scikit-learn)
![NLP](https://img.shields.io/badge/NLP-Preprocessing-6AC045?style=flat&logo=nltk)
![BERT](https://img.shields.io/badge/BERT-Embeddings-7933FF?style=flat&logo=transformers)
![UMAP](https://img.shields.io/badge/UMAP-Dimensionality_Reduction-00BFFF?style=flat)
![HDBSCAN](https://img.shields.io/badge/HDBSCAN-Clustering-FF4500?style=flat)

---

## ðŸ“˜ Overview *(Tá»•ng quan vÃ  Má»¥c tiÃªu)*

Project is a research project focusing on the **analysis and clustering of GitHub repositories** â€” an increasingly important problem due to the exponential growth of open-source ecosystems.  
*(Dá»± Ã¡n lÃ  má»™t nghiÃªn cá»©u táº­p trung vÃ o viá»‡c phÃ¢n tÃ­ch vÃ  phÃ¢n loáº¡i cÃ¡c dá»± Ã¡n GitHub â€” Ä‘iá»u nÃ y ráº¥t cáº§n thiáº¿t do sá»± phÃ¡t triá»ƒn nhanh chÃ³ng cá»§a cÃ¡c há»‡ sinh thÃ¡i mÃ£ nguá»“n má»Ÿ.)*

### ðŸ§© Importance of README.md *(Táº§m quan trá»ng cá»§a README.md)*
The **README.md** file plays a central role in open-source projects, providing essential information such as purpose, functionality, setup instructions, and usage.  
Hence, it serves as a **rich textual source** for semantic understanding and classification of software projects.  
*(README.md lÃ  tá»‡p cá»‘t lÃµi chá»©a mÃ´ táº£ má»¥c Ä‘Ã­ch, chá»©c nÄƒng, hÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  sá»­ dá»¥ng, nÃªn Ä‘Æ°á»£c coi lÃ  nguá»“n dá»¯ liá»‡u vÄƒn báº£n phong phÃº vÃ  Ä‘Ã¡ng tin cáº­y Ä‘á»ƒ hiá»ƒu vÃ  mÃ´ táº£ dá»± Ã¡n pháº§n má»m.)*

### ðŸŽ¯ Research Objective *(Má»¥c tiÃªu NghiÃªn cá»©u)*
To propose a **comprehensive framework** for clustering programming projects based on the **semantic information embedded in README.md** files â€” enabling topic discovery, trend analysis, and intelligent organization of software ecosystems.  
*(Äá» xuáº¥t má»™t khuÃ´n khá»• toÃ n diá»‡n cho viá»‡c phÃ¢n cá»¥m cÃ¡c dá»± Ã¡n láº­p trÃ¬nh dá»±a trÃªn thÃ´ng tin ngá»¯ nghÄ©a Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« cÃ¡c tá»‡p README.md â€” nháº±m khai phÃ¡ chá»§ Ä‘á», phÃ¢n tÃ­ch xu hÆ°á»›ng vÃ  tá»• chá»©c thÃ´ng minh há»‡ sinh thÃ¡i pháº§n má»m.)*

**Keywords:** GitHub, README.md, Text Clustering, TF-IDF, BERT Embeddings, K-Means, DBSCAN, HDBSCAN, UMAP, Unsupervised Learning.

---

## âš™ï¸ Methodology *(PhÆ°Æ¡ng phÃ¡p luáº­n)*

The study follows a **five-stage clustering pipeline**:  
*(NghiÃªn cá»©u Ã¡p dá»¥ng quy trÃ¬nh phÃ¢n cá»¥m gá»“m nÄƒm giai Ä‘oáº¡n chÃ­nh)*  
1. Data Collection *(Thu tháº­p dá»¯ liá»‡u)*  
2. Text Representation *(Biá»ƒu diá»…n vÄƒn báº£n)*  
3. Dimensionality Reduction *(Giáº£m chiá»u dá»¯ liá»‡u)*  
4. Clustering Algorithms *(Thuáº­t toÃ¡n phÃ¢n cá»¥m)*  
5. Evaluation Metrics *(ÄÃ¡nh giÃ¡ káº¿t quáº£)*  

---

### 1ï¸âƒ£ Data Collection *(Thu tháº­p Dá»¯ liá»‡u)*

| **Háº¡ng má»¥c** | **MÃ´ táº£ chi tiáº¿t** |
|---------------|--------------------|
| **Dataset size** | 57,383 README.md files |
| **Source** | GitHub GraphQL API (from 50+ distinct topics) |
| **Sampling strategy** | Collected across multiple ranking types: *Most Starred, Most Forked, Recently Updated, and Best Match* |
| **Deduplication** | Up to 1,000 unique repositories per topic were retained |

*(Tá»•ng cá»™ng 57.383 README.md Ä‘Æ°á»£c thu tháº­p tá»« hÆ¡n 50 chá»§ Ä‘á» GitHub riÃªng biá»‡t, sá»­ dá»¥ng 4 loáº¡i xáº¿p háº¡ng. QuÃ¡ trÃ¬nh khá»­ trÃ¹ng láº·p Ä‘áº£m báº£o tÃ­nh Ä‘a dáº¡ng vÃ  Ä‘áº¡i diá»‡n.)*

---

### 2ï¸âƒ£ Text Representation *(Biá»ƒu diá»…n VÄƒn báº£n)*

Two approaches were compared to capture **lexical and semantic information**:

| **PhÆ°Æ¡ng phÃ¡p** | **MÃ´ táº£ chi tiáº¿t** |
|------------------|--------------------|
| **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)** | Captures statistical word importance. Includes lowercase conversion, URL/code/Markdown removal, enhanced stopword list, and lemmatization. |
| **Sentence-BERT (all-MiniLM-L6-v2)** | Transformer-based model producing 384-dimensional sentence embeddings. Minimal preprocessing to preserve contextual meaning. |

*(NghiÃªn cá»©u so sÃ¡nh giá»¯a TF-IDF truyá»n thá»‘ng vÃ  Sentence-BERT hiá»‡n Ä‘áº¡i Ä‘á»ƒ náº¯m báº¯t Ä‘áº·c trÆ°ng ngá»¯ nghÄ©a sÃ¢u.)*

---

### 3ï¸âƒ£ Dimensionality Reduction *(Giáº£m Chiá»u Dá»¯ liá»‡u)*

- **Truncated SVD (Singular Value Decomposition):**  
  Applied to TF-IDF features â†’ reduced to 100 dimensions (â‰ˆ18.9% variance retained).  
- **UMAP (Uniform Manifold Approximation and Projection):**  
  Applied to BERT embeddings â†’ preserves local & global semantic structure for visualization.  

*(Giáº£m chiá»u giÃºp tÄƒng hiá»‡u quáº£ tÃ­nh toÃ¡n vÃ  phá»¥c vá»¥ trá»±c quan hÃ³a khÃ´ng gian ngá»¯ nghÄ©a.)*

---

### 4ï¸âƒ£ Clustering Algorithms *(Thuáº­t toÃ¡n PhÃ¢n cá»¥m)*

The study evaluates multiple algorithms for unsupervised learning:

| **Thuáº­t toÃ¡n** | **MÃ´ táº£ ngáº¯n gá»n** |
|----------------|--------------------|
| **K-Means** | Divides data into *K* clusters minimizing intra-cluster variance. |
| **DBSCAN** | Density-based clustering detecting noise and arbitrary shapes. |
| **Spectral Clustering** | Uses eigenvectors of Laplacian matrix for graph-based clustering. |
| **HDBSCAN** | Hierarchical version of DBSCAN that adapts to varying densities and auto-detects cluster count. |

---

### 5ï¸âƒ£ Evaluation Metrics *(Chá»‰ sá»‘ ÄÃ¡nh giÃ¡)*

As the task is **unsupervised**, internal clustering metrics were used:

| **Metric** | **Ã nghÄ©a** |
|-------------|-------------|
| **Silhouette Score** | Measures cohesion vs. separation (âˆ’1 â†’ 1). Higher = better-defined clusters. |
| **Daviesâ€“Bouldin Index (DB)** | Average similarity between each cluster and its most similar one. Lower = better. |
| **Calinskiâ€“Harabasz Score** | Ratio of between-cluster dispersion to within-cluster dispersion. Higher = better. |

---

## ðŸ“Š Experimental Results *(Káº¿t quáº£ Thá»±c nghiá»‡m)*

### ðŸ”¹ Performance Comparison

| **Representation** | **Algorithm** | **Silhouette** | **Observations** |
|---------------------|----------------|-----------------|------------------|
| TF-IDF + SVD | K-Means (k=79) | 0.0625 | Moderately compact clusters; weak separation based on surface keywords. |
| TF-IDF + SVD | Spectral Clustering | â€” | Captures more interpretable topic structures (e.g., server/API/Docker group 48.25%). |
| TF-IDF + SVD | DBSCAN | â€”- | Formed one dense cluster â†’ poor differentiation. |
| BERT Embeddings | K-Means (k=40) | 0.0269 | Overlapping semantic clusters; BERT space too continuous. |
| BERT Embeddings | HDBSCAN | **0.3057 (non-noise points)** | 17 clusters detected; 97.4% noise; semantically coherent â€œcore topics.â€ |

---

### ðŸ“ˆ Key Insights *(PhÃ¢n tÃ­ch ChÃ­nh)*

- **Trade-off between Quantitative and Semantic Performance:**  
  TF-IDF models perform better numerically but rely on surface-level tokens.  
  *(TF-IDF Ä‘áº¡t Ä‘iá»ƒm Ä‘á»‹nh lÆ°á»£ng cao hÆ¡n nhÆ°ng thiáº¿u chiá»u sÃ¢u ngá»¯ nghÄ©a.)*

- **Semantic Strength of BERT:**  
  BERT embeddings produce **conceptually cohesive** clusters despite lower numerical scores.  
  *(BERT thá»ƒ hiá»‡n cá»¥m ngá»¯ nghÄ©a sÃ¢u sáº¯c vÃ  sÃ¡t nghÄ©a, thá»ƒ hiá»‡n rÃµ trÃªn Ä‘á»“ thá»‹ UMAP.)*

- **Algorithm Sensitivity:**  
  Distance-based methods (K-Means, DBSCAN) struggle in high-dimensional semantic space.  
  *(CÃ¡c thuáº­t toÃ¡n dá»±a khoáº£ng cÃ¡ch gáº·p khÃ³ vá»›i khÃ´ng gian ngá»¯ nghÄ©a phá»©c táº¡p.)*

- **Optimal Combination:**  
  **BERT + HDBSCAN** yields the most **semantically meaningful** results â€” forming dense â€œtopic coresâ€ while filtering general/noisy repositories.  
  *(Káº¿t há»£p BERT vá»›i HDBSCAN Ä‘Æ°á»£c chá»©ng minh lÃ  tá»‘i Æ°u nháº¥t â€” phÃ¡t hiá»‡n cÃ¡c lÃµi chá»§ Ä‘á» rÃµ rÃ ng, Ä‘á»“ng thá»i xá»­ lÃ½ nhiá»…u hiá»‡u quáº£.)*


---

## ðŸ§  Conclusion *(Káº¿t luáº­n Tá»•ng thá»ƒ)*

This research demonstrates that **semantic embeddings (BERT)** combined with **density-based clustering (HDBSCAN)** produce **highly meaningful and conceptually coherent clusters** of programming projects.  
Capturing **contextual and semantic relationships** is crucial for effectively categorizing complex software ecosystems.

*(PhÆ°Æ¡ng phÃ¡p BERT + HDBSCAN mang láº¡i cÃ¡c cá»¥m ngá»¯ nghÄ©a sÃ¢u sáº¯c vÃ  cÃ³ Ã½ nghÄ©a nháº¥t. Viá»‡c náº¯m báº¯t má»‘i quan há»‡ ngá»¯ cáº£nh vÃ  ngá»¯ nghÄ©a lÃ  yáº¿u tá»‘ then chá»‘t trong phÃ¢n loáº¡i dá»± Ã¡n pháº§n má»m phá»©c táº¡p.)*



---

## ðŸ‘¥ Authors *(NhÃ³m Thá»±c hiá»‡n)*

**Students:** *(Sinh viÃªn thá»±c hiá»‡n)*  
- Há»“ Gia ThÃ nh  
- Huá»³nh ThÃ¡i Linh  
- TrÆ°Æ¡ng Minh Khoa  

**Supervisor:** *(Giáº£ng viÃªn hÆ°á»›ng dáº«n)* *ThS. LÃª Nháº­t TÃ¹ng*  
**University:** *(TrÆ°á»ng)* TrÆ°á»ng Äáº¡i há»c CÃ´ng nghá»‡ TP. Há»“ ChÃ­ Minh â€” *Khoa há»c Dá»¯ liá»‡u*  
**Year:** *(NÄƒm thá»±c hiá»‡n)* 2025

---

> Â© 2025 â€” Project: *Programming Project Clustering Based on README.md Text Analysis*  
> *Developed for academic research and educational purposes.*
